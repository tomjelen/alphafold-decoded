{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup\n",
    "\n",
    "Run the cells below for the basic setup of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No colab environment, assuming local setup.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive # type: ignore\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print('No colab environment, assuming local setup.')\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "    # turorials folder, e.g. 'alphafold-decoded/tutorials'\n",
    "    FOLDERNAME = None\n",
    "    assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "    # Now that we've mounted your Drive, this ensures that\n",
    "    # the Python interpreter of the Colab VM can load\n",
    "    # python files from within it.\n",
    "    import sys\n",
    "    sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "    %cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "\n",
    "    print('Connected COLAB to Google Drive.')\n",
    "\n",
    "import os\n",
    "\n",
    "base_folder = '../feature_extraction'\n",
    "control_folder = f'{base_folder}/control_values'\n",
    "\n",
    "assert os.path.isdir(control_folder), 'Folder \"control_values\" not found, make sure that FOLDERNAME is set correctly.' if IN_COLAB else 'Folder \"control_values\" not found, make sure that your root folder is set correctly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from control_values.obfuscated_solution import create_control_values\n",
    "\n",
    "# Some of the assert statements depend on the result of random operations,\n",
    "# which aren't always the same over different versions and operating systems.\n",
    "# Therefore, the control values are created directly on your system.\n",
    "create_control_values(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "In this Notebook, we will implement the feature extraction pipeline for AlphaFold. The pipeline consists of the following steps:\n",
    "\n",
    "- Parse the a3m file\n",
    "- Count and remove deletions (residues that are present in the aligned sequences, but aren't present in the query sequence)\n",
    "- Randomly select cluster centers\n",
    "- Randomly change some residues from the cluster center (this is called masking)\n",
    "- Assign non-cluster sequences to their closest cluster center by Hamming Distance\n",
    "- Summarize the features of all sequences assigned to the cluster\n",
    "- Select a fixed number of non-cluster sequences as extra sequences\n",
    "- Assemble the features\n",
    "\n",
    "Most of the work is done to create the `msa_feat` and the `extra_msa_feat`. The input features additionally consist of the `target_feat` and the `residue_index`, but these are easy to implement.\n",
    "\n",
    "For an overview of the features, you can read Section 1.2.9 from [AlphaFold's Supplement](https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-021-03819-2/MediaObjects/41586_2021_3819_MOESM1_ESM.pdf). \n",
    "\n",
    "We will skip over the template features in this series, but predictions often work great without them (ColabFold has the option to use templates disabled by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File parsing\n",
    "\n",
    "Take a look at the file `alignment_tautomerase.a3m`. In it, you will find the alignment data of the 2-Hydroxymuconate Tautomerase in a3m format. The alignment was generated by ColabFold, which uses the mmseqs algorithm to create alignments.\n",
    "\n",
    "Note the format of the file: It consists of lines starting with '>' containing an identifier and some values from the alignment, followed by a sequence. The first of these sequences is the query sequence.\n",
    "\n",
    "In the sequence string, there are upper-case and lower-case letters. Upper-case letters denote aligned residues, while lower-case letters denote residues that are present in the aligned sequence, but not in the query sequence (in other formats, this might be denoted by a dash in the query sequence). These are called deletions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this knowledge on the file format, implement the method `load_a3m_file` in the file `feature_extractor.py` and test your implementation with the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import load_a3m_file\n",
    "\n",
    "seqs = load_a3m_file(f'{base_folder}/alignment_tautomerase.a3m')\n",
    "\n",
    "first_expected = ['PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK', 'PVVTIELWEGRTPEQKRELVRAVSSAISRVLGCPEEAVHVILHEVPKANWGIGGRLASE', 'PVVTIEMWEGRTPEQKKALVEAVTSAVAGAIGCPPEAVEVIIHEVPKVNWGIGGQIASE', 'PIIQVQMLKGRSPELKKQLISEITDTISRTLGSPPEAVRVILTEVPEENWGVGGVPINE', 'PFVQIHMLEGRTPEQKKAVIEKVTQALVQAVGVPASAVRVLIQEVPKEHWGIGGVSARE']\n",
    "\n",
    "assert len(seqs) == 8361 and seqs[:5] == first_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will parse the individual sequence to remove deletions and encode them as one-hot encoding. For one-hot encoding, the classes must have a predetermined order. The usual way to order the residues is to alphabetically sort the 3-letter codes and to then use this order for the 1-letter codes. \n",
    "\n",
    "The order of the amino acids is provided at the top of `feature_extractor.py`. Initialize the two dictionaries as maps from the letter to the index. Then, implement `onehot_encode_aa_type` and check your implementation with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import onehot_encode_aa_type\n",
    "\n",
    "test_seq = \"ARNDCQEGHILKMFPSTWYV\"\n",
    "\n",
    "enc1 = onehot_encode_aa_type(test_seq, include_gap_token=False)\n",
    "enc2 = onehot_encode_aa_type(test_seq, include_gap_token=True)\n",
    "enc3 = onehot_encode_aa_type(test_seq+'-', include_gap_token=True)\n",
    "\n",
    "assert torch.allclose(enc1, nn.functional.one_hot(torch.arange(20), num_classes=21))\n",
    "assert torch.allclose(enc2, nn.functional.one_hot(torch.arange(20), num_classes=22))\n",
    "enc3_exp = nn.functional.one_hot(torch.cat((torch.arange(20),torch.tensor([21]))), num_classes=22)\n",
    "assert torch.allclose(enc3, enc3_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement `initial_data_from_seqs`. The method counts and removes deletions, and removes sequences that are duplicates (duplicates after removal of deletions). After that, the method uses one-hot encoding to encode the residues and calculates the distribution of the residues at each position.\n",
    "\n",
    "Test your code by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/1847380257.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_features = torch.load(f'{control_folder}/initial_data.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import initial_data_from_seqs\n",
    "seqs = load_a3m_file(f'{base_folder}/alignment_tautomerase.a3m')\n",
    "\n",
    "features = initial_data_from_seqs(seqs)\n",
    "\n",
    "expected_features = torch.load(f'{control_folder}/initial_data.pt')\n",
    "\n",
    "for key, param in features.items():\n",
    "    assert torch.allclose(param, expected_features[key]), f'Error in computation of feature {key}.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "A subset of the sequences is randomly selected as cluster centers, always including the query sequence as the first cluster center. Implement `select_cluster_centers` and test your implementation by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/535544868.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/initial_data.pt')\n",
      "/tmp/ipykernel_5949/535544868.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_features = torch.load(f'{control_folder}/clusters_selected.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import select_cluster_centers\n",
    "\n",
    "inp = torch.load(f'{control_folder}/initial_data.pt')\n",
    "\n",
    "features = select_cluster_centers(inp, seed=0)\n",
    "\n",
    "expected_features = torch.load(f'{control_folder}/clusters_selected.pt')\n",
    "\n",
    "for key, param in features.items():\n",
    "    assert torch.allclose(param, expected_features[key]), f'Error in computation of feature {key}.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlphaFold uses a regularization strategy they call 'masking' on the cluster centers (it is used during training and inference). \n",
    "\n",
    "This operation replaces some of the residues randomly according to the following rules:\n",
    "\n",
    "- 15% of the residues are selected. Of these,\n",
    "    - 10% are replaced with a uniformly sampled random amino acid.\n",
    "    - 10% are replaced with an amino acid sampled from the MSA distribution for this position.\n",
    "    - 10% are not replaced.\n",
    "    - 70% are replaced with a special token (masked_msa_token).\n",
    "\n",
    "For this, we will create a probability distribution of the replacement options for each amino acid, given that it falls under the first 15% (the first option for example contributes to the whole distribution by $[0.1\\cdot 1/20,\\, 0.1\\cdot 1/20, \\,0.1.\\cdot 1/20,...]$, the third option contributes to the whole distribution by [0, 0, 0.1, 0, 0, ...] given that the initial residue was N).\n",
    "\n",
    "After creation of the distribution, we will sample from it and create a mask with probability 15%. All amino acids in the mask are replaced by the amino acid sampled from the distribution.\n",
    "\n",
    "Implement the method `mask_cluster_centers`. You will find step-by-step instructions in the method body. After you're done, test your implementation by running the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/3056517401.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/clusters_selected.pt')\n",
      "/tmp/ipykernel_5949/3056517401.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_features = torch.load(f'{control_folder}/clusters_masked.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import mask_cluster_centers\n",
    "\n",
    "inp = torch.load(f'{control_folder}/clusters_selected.pt')\n",
    "\n",
    "features = mask_cluster_centers(inp, seed=1)\n",
    "\n",
    "expected_features = torch.load(f'{control_folder}/clusters_masked.pt')\n",
    "\n",
    "for key, param in features.items():\n",
    "    assert torch.allclose(param, expected_features[key]), f'Error in computation of feature {key}.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every sequence from the ExtraMSA is assigned to the cluster center it shares the most residues with. This is called Hamming-Distance. Implement the method `cluster_assignment` and check your implementation with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/2345045745.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/clusters_masked.pt')\n",
      "/tmp/ipykernel_5949/2345045745.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_features = torch.load(f'{control_folder}/clusters_assigned.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import cluster_assignment\n",
    "\n",
    "inp = torch.load(f'{control_folder}/clusters_masked.pt')\n",
    "\n",
    "features = cluster_assignment(inp)\n",
    "\n",
    "expected_features = torch.load(f'{control_folder}/clusters_assigned.pt')\n",
    "\n",
    "for key, param in features.items():\n",
    "    assert torch.allclose(param, expected_features[key]), f'Error in computation of feature {key}.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is used to reduce the computational cost of running the prediction to a manageable level. However, the information of the non-selected sequences should still contribute to the prediction. To do so, we calculate averages of the deletion_counts and the one-hot-encoded residues over the clusters.\n",
    "\n",
    "As the first step, implement the method `cluster_average`, that takes a feature, an extra_feature, the assignment indices and the assignment counts (how many extra sequences are assigned to each of the centers). You will find a step-by-step guide for the method in the method body. \n",
    "\n",
    "After you're done, check your implementation by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/918748440.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_res1 = torch.load(f'{control_folder}/cluster_average_res1.pt')\n",
      "/tmp/ipykernel_5949/918748440.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_res2 = torch.load(f'{control_folder}/cluster_average_res2.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import cluster_average\n",
    "\n",
    "# Check for cluster_average\n",
    "\n",
    "N_clust = 10\n",
    "N_res = 3\n",
    "N_extra = 20\n",
    "dim1 = 5\n",
    "dim2 = 7\n",
    "assignment = torch.tensor([7, 1, 1, 8, 3, 4, 7, 1, 4, 4, 9, 8, 4, 8, 1, 5, 8, 8, 8, 5])\n",
    "assignment_count = torch.tensor([0, 4, 0, 1, 4, 2, 0, 2, 6, 1])\n",
    "\n",
    "ft1_shape = (N_clust, N_res, dim1)\n",
    "eft1_shape = (N_extra, N_res, dim1)\n",
    "ft2_shape = (N_clust, N_res, dim1, dim2)\n",
    "eft2_shape = (N_extra, N_res, dim1, dim2)\n",
    "\n",
    "ft1 = torch.linspace(-2, 2, math.prod(ft1_shape)).reshape(ft1_shape)\n",
    "eft1 = torch.linspace(-2, 2, math.prod(eft1_shape)).reshape(eft1_shape)\n",
    "ft2 = torch.linspace(-2, 2, math.prod(ft2_shape)).reshape(ft2_shape)\n",
    "eft2 = torch.linspace(-2, 2, math.prod(eft2_shape)).reshape(eft2_shape)\n",
    "\n",
    "res1 = cluster_average(ft1, eft1, assignment, assignment_count)\n",
    "res2 = cluster_average(ft2, eft2, assignment, assignment_count)\n",
    "\n",
    "expected_res1 = torch.load(f'{control_folder}/cluster_average_res1.pt')\n",
    "expected_res2 = torch.load(f'{control_folder}/cluster_average_res2.pt')\n",
    "\n",
    "assert torch.allclose(res1, expected_res1)\n",
    "assert torch.allclose(res2, expected_res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use the method we just created to compute the average deletion counts and the cluster profiles. Implement the method `summarize_clusters` and check your code with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/2582658784.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/clusters_assigned.pt')\n",
      "/tmp/ipykernel_5949/2582658784.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_features = torch.load(f'{control_folder}/clusters_summarized.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import summarize_clusters\n",
    "\n",
    "inp = torch.load(f'{control_folder}/clusters_assigned.pt')\n",
    "\n",
    "features = summarize_clusters(inp)\n",
    "\n",
    "expected_features = torch.load(f'{control_folder}/clusters_summarized.pt')\n",
    "\n",
    "for key, param in features.items():\n",
    "    assert torch.allclose(param, expected_features[key]), f'Error in computation of feature {key}.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, the number of extra sequences was determined by the MSA algorithm (in our case mmseqs) and is, therefore, arbitrary. Of these extra sequences, we will randomly select a fixed number to directly contribute to the inference in form of the extra_msa_feat. This is done by the method `crop_extra_msa`. Implement it and check your code by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/3962976505.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/clusters_summarized.pt')\n",
      "/tmp/ipykernel_5949/3962976505.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_features = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import crop_extra_msa\n",
    "\n",
    "inp = torch.load(f'{control_folder}/clusters_summarized.pt')\n",
    "\n",
    "features = crop_extra_msa(inp, seed=2)\n",
    "\n",
    "expected_features = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n",
    "\n",
    "for key, param in features.items():\n",
    "    assert torch.allclose(param, expected_features[key]), f'Error in computation of feature {key}.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSA Feat and ExtraMSA Feat\n",
    "\n",
    "We've successfully populated the feature dict with all the features of the msa_feat. In the function `calculate_msa_feat`, we do some last processing on the features and concat them to get the finished msa_feat. The method description contains a step-by-step guide to assemble the feature. After you're done, check your implementation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/2763118081.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n",
      "/tmp/ipykernel_5949/2763118081.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_feat = torch.load(f'{control_folder}/msa_feat.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import calculate_msa_feat\n",
    "\n",
    "inp = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n",
    "\n",
    "msa_feat = calculate_msa_feat(inp)\n",
    "\n",
    "expected_feat = torch.load(f'{control_folder}/msa_feat.pt')\n",
    "\n",
    "assert torch.allclose(msa_feat, expected_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ExtraMSA feat is basically a simpler version of the MSA feat, as it doesn't include cluster averages. Implement `calculate_extra_msa_feat` and check your code with the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/4115297776.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n",
      "/tmp/ipykernel_5949/4115297776.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_feat = torch.load(f'{control_folder}/extra_msa_feat.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import calculate_extra_msa_feat\n",
    "\n",
    "inp = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n",
    "\n",
    "msa_feat = calculate_extra_msa_feat(inp)\n",
    "\n",
    "expected_feat = torch.load(f'{control_folder}/extra_msa_feat.pt')\n",
    "\n",
    "assert torch.allclose(msa_feat, expected_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "We've got all the methods to build the complete input for AlphaFold. `create_features_from_a3m` walks you through putting together all the methods we defined so far. Note that we'll construct two new features:\n",
    "- target_feat: One-hot encoded query sequence\n",
    "- residue_index: Index of each residue, simply [0,...,N_res-1] for our prediction.\n",
    "\n",
    "After you are done with your implementation, check your code by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5949/315892125.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inp = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n",
      "/tmp/ipykernel_5949/315892125.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expected_batch = torch.load(f'{control_folder}/full_batch.pt')\n"
     ]
    }
   ],
   "source": [
    "from feature_extraction import create_features_from_a3m\n",
    "\n",
    "inp = torch.load(f'{control_folder}/extra_msa_cropped.pt')\n",
    "\n",
    "batch = create_features_from_a3m(f'{base_folder}/alignment_tautomerase.a3m', seed=0)\n",
    "\n",
    "expected_batch = torch.load(f'{control_folder}/full_batch.pt')\n",
    "\n",
    "for key, param in batch.items():\n",
    "    assert torch.allclose(param, expected_batch[key]), f'Error in computation of feature {key}.'\n",
    "\n",
    "assert batch['target_feat'].dtype == torch.float32, f\"Target feat isn't a float, but {batch['target_feat'].dtype}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've completed the feature extraction for AlphaFold – nice work! That step can get a bit tricky. Next up is the Evoformer. Since we've already implemented the MultiHeadAttention module, this part should feel more straightforward. It's where your features start turning into the insights that drive the Structure Module.  See you there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My notes\n",
    "\n",
    "### mask_cluster_centers\n",
    "\n",
    "- Todo says `Create a copy of the original 'msa_aatype' data under the key 'true_msa_atype'.`. But this leads to a failure in the cell that asserts the method.\n",
    "- I feel uneasy about adding the padding category to `msa_aatype`. I have changed the meaning of the one-hot encoding that it originally had, meaning callers have to be aware of when this method can be called, and that it cannot be called multiple times, etc.. I could be worth considering to make the mask a part of the input `msa_aatype` instead of changing it during the call.\n",
    "\n",
    "### cluster_average\n",
    "\n",
    "- It was actually difficult to get my head around what the inputs to the method were. I think if I had seen an example usage in the tests, I would have understood it better. In general, loading stuff from the control-folder and asserting against them in the tests, makes it hard to use the tests as documentation, or in this instance, a guide to understand the code to be implemented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
